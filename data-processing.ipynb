{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "import os\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     title                                id  \\\n",
      "0  2006 Pangandaran earthquake and tsunami  8307a6b61b84d4eea42c1dd5e6e2cdba   \n",
      "1             Battle of Santa Clara (1927)  387fe1dfe55067eb29e1fd4116d37af3   \n",
      "2              Siege of Pondicherry (1793)  268c4763208c87ed7ebf55565c274d23   \n",
      "3                        Battle of Leuthen  c95e68565081126b5c949117e423695a   \n",
      "4           Glasgow St Enoch rail accident  3bec0b60c0940c5e46ee2cfc9504df92   \n",
      "\n",
      "                                             content  \\\n",
      "0  [{'sentence': 'The 2006 Pangandaran earthquake...   \n",
      "1  [{'sentence': 'The Battle of Santa Clara took ...   \n",
      "2  [{'sentence': '\"For other sieges with this nam...   \n",
      "3  [{'sentence': 'The Battle of Leuthen was fough...   \n",
      "4  [{'sentence': 'The Glasgow St Enoch rail accid...   \n",
      "\n",
      "                                              events  \\\n",
      "0  [{'id': '40b3b20bc2eeb6b163538b82c1379ead', 't...   \n",
      "1  [{'id': '966f55ccc3fc199e066929414c392266', 't...   \n",
      "2  [{'id': 'f23b13a5a4bf219bfff703cb35c4728c', 't...   \n",
      "3  [{'id': '88b1466d9e6a4bbc5be1558b0db69c0a', 't...   \n",
      "4  [{'id': 'f6c88043b6e3f9ea5d9cd2a610d8dab0', 't...   \n",
      "\n",
      "                                   negative_triggers  \n",
      "0  [{'trigger_word': 'populated', 'sent_id': 0, '...  \n",
      "1  [{'trigger_word': 'aircraft', 'sent_id': 3, 'o...  \n",
      "2  [{'trigger_word': 'sieges', 'sent_id': 0, 'off...  \n",
      "3  [{'trigger_word': 'action', 'sent_id': 4, 'off...  \n",
      "4  [{'trigger_word': 'Glasgow', 'sent_id': 0, 'of...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Specify the path to the directory containing the data\n",
    "data_directory = '../50.021-ai-event-detection/data'\n",
    "\n",
    "# Construct the absolute path to the JSONL file\n",
    "jsonl_path = os.path.join(data_directory, 'train.jsonl')\n",
    "\n",
    "# Read the content of the JSONL file\n",
    "with open(jsonl_path, 'r', encoding='utf-8') as file:\n",
    "    json_content = file.read()\n",
    "\n",
    "# Wrap the JSON content in a StringIO object\n",
    "json_io = StringIO(json_content)\n",
    "\n",
    "# Read the JSONL content from StringIO object\n",
    "df = pd.read_json(json_io, lines=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2913, 5)\n",
      "Unique categories: 2913\n",
      "-------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2913 entries, 0 to 2912\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   title              2913 non-null   object\n",
      " 1   id                 2913 non-null   object\n",
      " 2   content            2913 non-null   object\n",
      " 3   events             2913 non-null   object\n",
      " 4   negative_triggers  2913 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 113.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# shape of the dataset\n",
    "print(df.shape)\n",
    "# total number of unique categories\n",
    "print(\"Unique categories:\",df['title'].nunique())\n",
    "print(\"-------------------------------------------------\")\n",
    "# information about metadata\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006 Pangandaran earthquake and tsunami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Battle of Santa Clara (1927)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Siege of Pondicherry (1793)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Battle of Leuthen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Glasgow St Enoch rail accident</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     title\n",
       "0  2006 Pangandaran earthquake and tsunami\n",
       "1             Battle of Santa Clara (1927)\n",
       "2              Siege of Pondicherry (1793)\n",
       "3                        Battle of Leuthen\n",
       "4           Glasgow St Enoch rail accident"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop irrelevant columns\n",
    "df['type'] = df['events'].apply(lambda x: x[0]['type'] if x else None)\n",
    "new_df = df[['title']]\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        title\n",
      "0     2006 Pangandaran earthquake and tsunami\n",
      "1                Battle of Santa Clara (1927)\n",
      "2                 Siege of Pondicherry (1793)\n",
      "3                           Battle of Leuthen\n",
      "4              Glasgow St Enoch rail accident\n",
      "...                                       ...\n",
      "2908           1979 Football League Cup Final\n",
      "2909                   K-1 Premium Dynamite!!\n",
      "2910                       2002 Hebron ambush\n",
      "2911       Minneapolis general strike of 1934\n",
      "2912                      Spanair Flight 5022\n",
      "\n",
      "[2913 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_22096\\1209090852.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['word_count'] = new_df['title'].str.split().str.len()\n"
     ]
    }
   ],
   "source": [
    "# Split the string into words using split() and then get the length of resulting list of title\n",
    "new_df['word_count'] = new_df['title'].str.split().str.len()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        title  word_count\n",
      "0     2006 Pangandaran earthquake and tsunami           5\n",
      "1                Battle of Santa Clara (1927)           5\n",
      "2                 Siege of Pondicherry (1793)           4\n",
      "3                           Battle of Leuthen           3\n",
      "4              Glasgow St Enoch rail accident           5\n",
      "...                                       ...         ...\n",
      "2908           1979 Football League Cup Final           5\n",
      "2909                   K-1 Premium Dynamite!!           3\n",
      "2910                       2002 Hebron ambush           3\n",
      "2911       Minneapolis general strike of 1934           5\n",
      "2912                      Spanair Flight 5022           3\n",
      "\n",
      "[2913 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_22096\\2608445191.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['character_count'] = new_df['title'].str.len()\n"
     ]
    }
   ],
   "source": [
    "# Get character length of the title\n",
    "new_df['character_count'] = new_df['title'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        title  word_count  character_count\n",
      "0     2006 Pangandaran earthquake and tsunami           5               39\n",
      "1                Battle of Santa Clara (1927)           5               28\n",
      "2                 Siege of Pondicherry (1793)           4               27\n",
      "3                           Battle of Leuthen           3               17\n",
      "4              Glasgow St Enoch rail accident           5               30\n",
      "...                                       ...         ...              ...\n",
      "2908           1979 Football League Cup Final           5               30\n",
      "2909                   K-1 Premium Dynamite!!           3               22\n",
      "2910                       2002 Hebron ambush           3               18\n",
      "2911       Minneapolis general strike of 1934           5               34\n",
      "2912                      Spanair Flight 5022           3               19\n",
      "\n",
      "[2913 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate n-grams for the title\n",
    "def generate_ngrams(text, n):\n",
    "    # Tokenize the text into words\n",
    "    tokens = word_tokenize(text)\n",
    "    # Generate n-grams\n",
    "    return list(ngrams(tokens, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_22096\\3546947482.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['bigrams'] = new_df['title'].apply(lambda title: generate_ngrams(title, n))\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "new_df['bigrams'] = new_df['title'].apply(lambda title: generate_ngrams(title, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        title  word_count  character_count  \\\n",
      "0     2006 Pangandaran earthquake and tsunami           5               39   \n",
      "1                Battle of Santa Clara (1927)           5               28   \n",
      "2                 Siege of Pondicherry (1793)           4               27   \n",
      "3                           Battle of Leuthen           3               17   \n",
      "4              Glasgow St Enoch rail accident           5               30   \n",
      "...                                       ...         ...              ...   \n",
      "2908           1979 Football League Cup Final           5               30   \n",
      "2909                   K-1 Premium Dynamite!!           3               22   \n",
      "2910                       2002 Hebron ambush           3               18   \n",
      "2911       Minneapolis general strike of 1934           5               34   \n",
      "2912                      Spanair Flight 5022           3               19   \n",
      "\n",
      "                                                bigrams  \n",
      "0     [(2006, Pangandaran), (Pangandaran, earthquake...  \n",
      "1     [(Battle, of), (of, Santa), (Santa, Clara), (C...  \n",
      "2     [(Siege, of), (of, Pondicherry), (Pondicherry,...  \n",
      "3                         [(Battle, of), (of, Leuthen)]  \n",
      "4     [(Glasgow, St), (St, Enoch), (Enoch, rail), (r...  \n",
      "...                                                 ...  \n",
      "2908  [(1979, Football), (Football, League), (League...  \n",
      "2909  [(K-1, Premium), (Premium, Dynamite), (Dynamit...  \n",
      "2910                 [(2002, Hebron), (Hebron, ambush)]  \n",
      "2911  [(Minneapolis, general), (general, strike), (s...  \n",
      "2912                [(Spanair, Flight), (Flight, 5022)]  \n",
      "\n",
      "[2913 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "war flight hurricane battle tour air airlines bombing second siege\n",
      "Topic #1:\n",
      "hurricane massacre festival 2011 2005 summer olympics tour 2014 2000\n",
      "Topic #2:\n",
      "hurricane action siege crash revolution 2010 2013 disaster rail massacre\n",
      "Topic #3:\n",
      "operation festival war invasion hurricane civil indian games north cyclone\n",
      "Topic #4:\n",
      "battle world cup storm tour tropical final league championship 2009\n"
     ]
    }
   ],
   "source": [
    "# Use CountVectorizer to convert a collection of text documents to a matrix of token counts\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(new_df['title'])\n",
    "\n",
    "# Set the number of topics\n",
    "n_topics = 5\n",
    "\n",
    "# Initialize LDA\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, random_state=0)\n",
    "lda.fit(X)\n",
    "\n",
    "# Get the words that are most common in each topic\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic #{topic_idx}:\")\n",
    "    print(\" \".join([feature_names[i] for i in topic.argsort()[:-10 - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
