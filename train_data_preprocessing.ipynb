{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Get trigger words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/test/preprocess_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_digit(word):\n",
    "    for char in word:\n",
    "        if char.isdigit():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def extract_contextual_words(title):\n",
    "    result = []\n",
    "    pos_tag = ['ADJ', 'NOUN', 'VERB', 'ADV', 'NNP'] \n",
    "    tag_ls = ['NN', 'NNP']\n",
    "    label_type = ['TIME', 'PERCENT', 'MONEY', 'QUANTITY', 'ORDINAL', 'CARDINAL']\n",
    "    doc = nlp(title[0].lower()+title[1:])\n",
    "\n",
    "    for token in doc:\n",
    "        if token.text in nlp.Defaults.stop_words or token.text in punctuation or contains_digit(token.text):\n",
    "            continue\n",
    "        #print(token.text, token.pos_, token.tag_, token.dep_, token.ent_type_)\n",
    "        if((token.pos_ in pos_tag) or (token.tag_ in tag_ls)) and (token.ent_type_ not in label_type):\n",
    "            result.append(token.text.lower())\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['michael', 'jackson', 'memorial', 'service']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_contextual_words(\"Michael Jackson memorial service\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['contextual_words'] = df['title'].apply(extract_contextual_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['contextual_words'].map(len) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Get TF-IDF of trigger words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df['title'])\n",
    "words = vectorizer.get_feature_names_out()\n",
    "tfidf_scores = tfidf_matrix.sum(axis=0).A1\n",
    "word_scores = dict(zip(words, tfidf_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['context_score'] = None\n",
    "for index, row in df.iterrows():\n",
    "    score = {}\n",
    "    for word in row['contextual_words']:\n",
    "        if word in word_scores:\n",
    "            score[word] = word_scores[word]\n",
    "        else:\n",
    "            score[word] = 0\n",
    "            \n",
    "    if len(score) > 0:\n",
    "        max_score = max(score.values())\n",
    "        if max_score > 0:\n",
    "            for key in score:\n",
    "                score[key] = score[key] / max_score\n",
    "        \n",
    "    score = {k: v for k, v in score.items() if v > 0.5}\n",
    "    \n",
    "    df.at[index, 'context_score'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[['title', 'context_score']]\n",
    "new_df = new_df[new_df['context_score'].map(len) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('data/test/output_with_context_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Get category of trigger words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_relatedness(word1, word2):\n",
    "    max_similarity = 0\n",
    "    \n",
    "    # Iterate through all synsets of each word\n",
    "    for synset1 in wordnet.synsets(word1):\n",
    "        for synset2 in wordnet.synsets(word2):\n",
    "            similarity = synset1.wup_similarity(synset2)\n",
    "            if similarity is not None and similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "    \n",
    "    return max_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_representative_word(words_to_check):\n",
    "    common_hypernyms = Counter()\n",
    "\n",
    "    for word in words_to_check:\n",
    "        synsets = wordnet.synsets(word)\n",
    "        for synset in synsets:\n",
    "            common_hypernyms.update(synset.hypernyms())\n",
    "\n",
    "    if not common_hypernyms:\n",
    "        return None\n",
    "    \n",
    "    return common_hypernyms.most_common(1)[0][0].lemma_names()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_row(current_categories, df_row):\n",
    "    if len(current_categories) > 0:\n",
    "        cat_word_scores = {}\n",
    "        for category in current_categories:\n",
    "            for word in df_row['context_score'].keys():\n",
    "                cat_word_scores[(category, word)] = words_relatedness(word, category)\n",
    "        \n",
    "        max_score = max(cat_word_scores.values())\n",
    "        if max_score > 0.8:\n",
    "            new_category = [k[0] for k, v in cat_word_scores.items() if v == max_score][0]\n",
    "            return current_categories, new_category\n",
    "        \n",
    "    new_category = find_representative_word(df_row['context_score'].keys())\n",
    "    if new_category == None:\n",
    "        new_category = max(df_row['context_score'], key=df_row['context_score'].get)\n",
    "    \n",
    "    if new_category not in current_categories:\n",
    "        current_categories.append(new_category)\n",
    "        \n",
    "    return current_categories, new_category\n",
    "\n",
    "\n",
    "def get_category_df(df, current_categories):\n",
    "    df['category'] = None\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            current_categories, category = get_category_row(current_categories, row)\n",
    "            df.at[idx, 'category'] = category\n",
    "        except Exception as e:\n",
    "            print(\"Error at %d: %s\" % (idx, e))\n",
    "            print(current_categories)\n",
    "            break\n",
    "    \n",
    "    return df, current_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_df, current_categories = get_category_df(new_df, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_df.to_csv('data/test/output_with_category.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "three_nine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
