{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Get trigger words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/test/preprocess_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_digit(word):\n",
    "    for char in word:\n",
    "        if char.isdigit():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def extract_contextual_words(title):\n",
    "    result = []\n",
    "    pos_tag = ['ADJ', 'NOUN', 'VERB', 'ADV', 'NNP'] \n",
    "    tag_ls = ['NN', 'NNP']\n",
    "    label_type = ['TIME', 'PERCENT', 'MONEY', 'QUANTITY', 'ORDINAL', 'CARDINAL']\n",
    "    doc = nlp(title[0].lower()+title[1:])\n",
    "\n",
    "    for token in doc:\n",
    "        if token.text in nlp.Defaults.stop_words or token.text in punctuation or contains_digit(token.text):\n",
    "            continue\n",
    "        #print(token.text, token.pos_, token.tag_, token.dep_, token.ent_type_)\n",
    "        if((token.pos_ in pos_tag) or (token.tag_ in tag_ls)) and (token.ent_type_ not in label_type):\n",
    "            result.append(token.text.lower())\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['michael', 'jackson', 'memorial', 'service']"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_contextual_words(\"Michael Jackson memorial service\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['contextual_words'] = df['title'].apply(extract_contextual_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['contextual_words'].map(len) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Get TF-IDF of trigger words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df['title'])\n",
    "words = vectorizer.get_feature_names_out()\n",
    "tfidf_scores = tfidf_matrix.sum(axis=0).A1\n",
    "word_scores = dict(zip(words, tfidf_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['context_score'] = None\n",
    "for index, row in df.iterrows():\n",
    "    score = {}\n",
    "    for word in row['contextual_words']:\n",
    "        if word in word_scores:\n",
    "            score[word] = word_scores[word]\n",
    "        else:\n",
    "            score[word] = 0\n",
    "            \n",
    "    if len(score) > 0:\n",
    "        max_score = max(score.values())\n",
    "        if max_score > 0:\n",
    "            for key in score:\n",
    "                score[key] = score[key] / max_score\n",
    "        \n",
    "    score = {k: v for k, v in score.items() if v > 0.5}\n",
    "    \n",
    "    df.at[index, 'context_score'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[['title', 'context_score']]\n",
    "new_df = new_df[new_df['context_score'].map(len) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('data/test/output_with_context_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Get category of trigger words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from collections import Counter\n",
    "\n",
    "def words_relatedness(word1, word2):\n",
    "    max_similarity = 0\n",
    "    \n",
    "    # Iterate through all synsets of each word\n",
    "    for synset1 in wordnet.synsets(word1):\n",
    "        for synset2 in wordnet.synsets(word2):\n",
    "            similarity = synset1.wup_similarity(synset2)\n",
    "            if similarity is not None and similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "    \n",
    "    return max_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_representative_word(words_to_check):\n",
    "    common_hypernyms = Counter()\n",
    "\n",
    "    for word in words_to_check:\n",
    "        synsets = wordnet.synsets(word)\n",
    "        for synset in synsets:\n",
    "            common_hypernyms.update(synset.hypernyms())\n",
    "\n",
    "    if not common_hypernyms:\n",
    "        return None\n",
    "    \n",
    "    return common_hypernyms.most_common(1)[0][0].lemma_names()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_row(current_categories, df_row):\n",
    "    if len(current_categories) > 0:\n",
    "        cat_word_scores = {}\n",
    "        for category in current_categories:\n",
    "            for word in df_row['context_score'].keys():\n",
    "                cat_word_scores[(category, word)] = words_relatedness(word, category)\n",
    "        \n",
    "        max_score = max(cat_word_scores.values())\n",
    "        if max_score > 0.8:\n",
    "            new_category = [k[0] for k, v in cat_word_scores.items() if v == max_score][0]\n",
    "            return current_categories, new_category\n",
    "        \n",
    "    new_category = find_representative_word(df_row['context_score'].keys())\n",
    "    if new_category == None:\n",
    "        new_category = max(df_row['context_score'], key=df_row['context_score'].get)\n",
    "    \n",
    "    if new_category not in current_categories:\n",
    "        current_categories.append(new_category)\n",
    "        \n",
    "    return current_categories, new_category\n",
    "\n",
    "\n",
    "def get_category_df(df, current_categories):\n",
    "    df['category'] = None\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            current_categories, category = get_category_row(current_categories, row)\n",
    "            df.at[idx, 'category'] = category\n",
    "        except Exception as e:\n",
    "            print(\"Error at %d: %s\" % (idx, e))\n",
    "            print(current_categories)\n",
    "            break\n",
    "    \n",
    "    return df, current_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_df, current_categories = get_category_df(new_df, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'category_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcategory_df\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/test/output_with_category.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'category_df' is not defined"
     ]
    }
   ],
   "source": [
    "category_df.to_csv('data/test/output_with_category.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "three_nine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
