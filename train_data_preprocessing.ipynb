{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/test/preprocess_output.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Get contextual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contextual_features(title):\n",
    "    doc = nlp(title)\n",
    "    lemma = []\n",
    "    pos = []\n",
    "    tag = []\n",
    "    dep = []\n",
    "    label = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.text in punctuation:\n",
    "            continue\n",
    "        lemma.append(token.lemma_)\n",
    "        pos.append(token.pos_)\n",
    "        tag.append(token.tag_)\n",
    "        dep.append(token.dep_)\n",
    "        label.append(token.ent_type_)\n",
    "        \n",
    "    return lemma, pos, tag, dep, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = []\n",
    "pos = []\n",
    "tag = []\n",
    "dep = []\n",
    "label = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    title = row['title']\n",
    "    l, p, t, d, la = get_contextual_features(title)\n",
    "    lemma.append(l)\n",
    "    pos.append(p)\n",
    "    tag.append(t)\n",
    "    dep.append(d)\n",
    "    label.append(la)\n",
    "\n",
    "df['lemma'] = lemma\n",
    "df['pos'] = pos\n",
    "df['tag'] = tag\n",
    "df['dep'] = dep\n",
    "df['label'] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Get trigger words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_digit(word):\n",
    "    for char in word:\n",
    "        if char.isdigit():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def extract_trigger_words(title):\n",
    "    result = []\n",
    "    pos_tag = ['ADJ', 'NOUN', 'VERB', 'ADV', 'NNP'] \n",
    "    tag_ls = ['NN', 'NNP']\n",
    "    label_type = ['TIME', 'PERCENT', 'MONEY', 'QUANTITY', 'ORDINAL', 'CARDINAL']\n",
    "    doc = nlp(title[0].lower()+title[1:])\n",
    "\n",
    "    for token in doc:\n",
    "        if token.text in nlp.Defaults.stop_words or token.text in punctuation or contains_digit(token.text):\n",
    "            continue\n",
    "        #print(token.text, token.pos_, token.tag_, token.dep_, token.ent_type_)\n",
    "        if((token.pos_ in pos_tag) or (token.tag_ in tag_ls)) and (token.ent_type_ not in label_type):\n",
    "            result.append(token.text.lower())\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['michael', 'jackson', 'memorial', 'service']"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_trigger_words(\"Michael Jackson memorial service\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trigger_words'] = df['title'].apply(extract_trigger_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['trigger_words'].map(len) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Get TF-IDF of trigger words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df['title'])\n",
    "words = vectorizer.get_feature_names_out()\n",
    "tfidf_scores = tfidf_matrix.sum(axis=0).A1\n",
    "word_scores = dict(zip(words, tfidf_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['context_score'] = None\n",
    "for index, row in df.iterrows():\n",
    "    score = {}\n",
    "    for word in row['trigger_words']:\n",
    "        if word in word_scores:\n",
    "            score[word] = word_scores[word]\n",
    "        else:\n",
    "            score[word] = 0\n",
    "            \n",
    "    if len(score) > 0:\n",
    "        max_score = max(score.values())\n",
    "        if max_score > 0:\n",
    "            for key in score:\n",
    "                score[key] = score[key] / max_score\n",
    "        \n",
    "    score = {k: v for k, v in score.items() if v > 0.5}\n",
    "    \n",
    "    df.at[index, 'context_score'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['context_score'].map(len) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/test/output_with_context_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Get category of trigger words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jeremychua/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_relatedness(word1, word2):\n",
    "    max_similarity = 0\n",
    "    \n",
    "    # Iterate through all synsets of each word\n",
    "    for synset1 in wordnet.synsets(word1):\n",
    "        for synset2 in wordnet.synsets(word2):\n",
    "            similarity = synset1.wup_similarity(synset2)\n",
    "            if similarity is not None and similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "    \n",
    "    return max_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_representative_word(words_to_check):\n",
    "    common_hypernyms = Counter()\n",
    "\n",
    "    for word in words_to_check:\n",
    "        synsets = wordnet.synsets(word)\n",
    "        for synset in synsets:\n",
    "            common_hypernyms.update(synset.hypernyms())\n",
    "\n",
    "    if not common_hypernyms:\n",
    "        return None\n",
    "    \n",
    "    return common_hypernyms.most_common(1)[0][0].lemma_names()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_row(current_categories, df_row):\n",
    "    if len(current_categories) > 0:\n",
    "        cat_word_scores = {}\n",
    "        for category in current_categories:\n",
    "            for word in df_row['context_score'].keys():\n",
    "                cat_word_scores[(category, word)] = words_relatedness(word, category)\n",
    "        \n",
    "        max_score = max(cat_word_scores.values())\n",
    "        if max_score > 0.8:\n",
    "            new_category = [k[0] for k, v in cat_word_scores.items() if v == max_score][0]\n",
    "            return current_categories, new_category\n",
    "        \n",
    "    new_category = find_representative_word(df_row['context_score'].keys())\n",
    "    if new_category == None:\n",
    "        new_category = max(df_row['context_score'], key=df_row['context_score'].get)\n",
    "    \n",
    "    if new_category not in current_categories:\n",
    "        current_categories.append(new_category)\n",
    "        \n",
    "    return current_categories, new_category\n",
    "\n",
    "\n",
    "def get_category_df(df, current_categories):\n",
    "    df['category'] = None\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            current_categories, category = get_category_row(current_categories, row)\n",
    "            df.at[idx, 'category'] = category\n",
    "        except Exception as e:\n",
    "            print(\"Error at %d: %s\" % (idx, e))\n",
    "            print(current_categories)\n",
    "            break\n",
    "    \n",
    "    return df, current_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_df, current_categories = get_category_df(df, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['title', 'lemma', 'pos', 'tag', 'dep', 'label', 'context_score', 'trigger_words']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_df.to_csv('data/test/output_with_category.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "three_nine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
